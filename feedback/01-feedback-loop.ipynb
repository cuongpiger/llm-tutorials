{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4e1202233dfc9a8",
   "metadata": {},
   "source": [
    "# RAG system with Feedback loop: Enhancing Retrieval and Response Quality\n",
    "## 1. Overview\n",
    "- This system implements a Retrieval-Augmented Generation (RAG) approach with an **integrated feedback loop**.\n",
    "- It aims to improve the quality and relevance of responses over time by incorporating user feedback and dynamically adjusting the retrieval process.\n",
    "\n",
    "## 2. Motivation\n",
    "- Traditional RAG systems can sometimes produce inconsistent or irrelevant responses due to limitations in the retrieval process or the underlying knowledge base. By implementing a feedback loop, we can:\n",
    "  - Continuously improve the quality of retrieved documents\n",
    "  - Enhance the relevance of generated responses\n",
    "  - Adapt the system to user preferences and needs over time\n",
    "\n",
    "## 3. Key components\n",
    "  1. **PDF Content Extraction**: Extracts text from PDF documents\n",
    "  2. **Vectorstore**: Stores and indexes document embeddings for efficient retrieval\n",
    "  3. **Retriever**: Fetches relevant documents based on user queries\n",
    "  4. **Language Model**: Generates responses using retrieved documents\n",
    "  5. **Feedback Collection**: Gathers user feedback on response quality and relevance\n",
    "  6. **Feedback Storage**: Persists user feedback for future use\n",
    "  7. **Relevance Score Adjustment**: Modifies document relevance based on feedback\n",
    "  8 **Index Fine-tuning**: Periodically updates the vectorstore using accumulated feedback\n",
    "\n",
    "## 4. Method Details\n",
    "### 4.1. Initial Setup\n",
    "- The system reads PDF content and creates a vectorstore\n",
    "- A retriever is initialized using the vectorstore\n",
    "- A language model (LLM) is set up for response generation\n",
    "\n",
    "### 4.2. Query Processing\n",
    "- When a user submits a query, the retriever fetches relevant documents\n",
    "- The LLM generates a response based on the retrieved documents\n",
    "\n",
    "### 4.3. Feedback Collection\n",
    "- The system collects user feedback on the response's relevance and quality\n",
    "- Feedback is stored in a JSON file for persistence\n",
    "\n",
    "### 4.4. Relevance Score Adjustment\n",
    "- For subsequent queries, the system loads previous feedback\n",
    "- An LLM evaluates the relevance of past feedback to the current query\n",
    "- Document relevance scores are adjusted based on this evaluation\n",
    "\n",
    "### 4.5. Retriever Update\n",
    "- The retriever is updated with the adjusted document scores\n",
    "- This ensures that future retrievals benefit from past feedback\n",
    "\n",
    "### 4.6. Periodic Index Fine-tuning\n",
    "- At regular intervals, the system fine-tunes the index\n",
    "- High-quality feedback is used to create additional documents\n",
    "- The vectorstore is updated with these new documents, improving overall retrieval quality\n",
    "\n",
    "## 5. Benefits of this Approach\n",
    "- **Continuous Improvement**: The system learns from each interaction, gradually enhancing its performance.\n",
    "- **Personalization**: By incorporating user feedback, the system can adapt to individual or group preferences over time.\n",
    "- **Increased Relevance**: The feedback loop helps prioritize more relevant documents in future retrievals.\n",
    "- **Quality Control**: Low-quality or irrelevant responses are less likely to be repeated as the system evolves.\n",
    "- **Adaptability**: The system can adjust to changes in user needs or document contents over time.\n",
    "\n",
    "## 6. Conclusion\n",
    "- This RAG system with a feedback loop represents a significant advancement over traditional RAG implementations. By continuously learning from user interactions, it offers a more dynamic, adaptive, and user-centric approach to information retrieval and response generation. This system is particularly valuable in domains where information accuracy and relevance are critical, and where user needs may evolve over time.\n",
    "- While the implementation adds complexity compared to a basic RAG system, the benefits in terms of response quality and user satisfaction make it a worthwhile investment for applications requiring high-quality, context-aware information retrieval and generation.\n",
    "\n",
    "  <center>\n",
    "    <image src=\"./../assets/images/feedback/01.svg\" width=\"auto\" height=\"1000\" />\n",
    "  </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29214f71b6653f57",
   "metadata": {},
   "source": [
    "##### Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aacd428c71148dac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T04:28:25.945074Z",
     "start_time": "2025-03-04T04:28:25.934517Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a8b16ae6d9f242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T04:47:06.081231Z",
     "start_time": "2025-03-04T04:47:05.939779Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # Add the parent directory to the path sicnce we work with notebooks\n",
    "\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b821e2a48c0ab5",
   "metadata": {},
   "source": [
    "##### Define the document path and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3eb315cab937234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T04:28:26.618142Z",
     "start_time": "2025-03-04T04:28:26.606800Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"../data/vks/pdf/vi/01-vks-la-gi.pdf\"\n",
    "\n",
    "ENV_FILE_PATH = \"/Users/cuongdm8499/Me/git-cuongpiger/secret/work/vngcloud/ai-platform/env\"\n",
    "MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B\"\n",
    "MAX_TOKENS = 32700\n",
    "\n",
    "envs = load_env_to_dict(ENV_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62454d99eddc5f7f",
   "metadata": {},
   "source": [
    "##### Create vector store and retrieval QA chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d26ebbe2adb103ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T04:28:34.306448Z",
     "start_time": "2025-03-04T04:28:26.634550Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llm-evaluation/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "content = read_pdf_to_string(path)\n",
    "vectorstore = encode_from_string(content)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=\"EMPTY\",\n",
    "    openai_api_base=envs['VLLM_HOST_URL_2'] + \"/v1/\",\n",
    "    model_name=MODEL_NAME,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    streaming=True,\n",
    "    stop=[\"<|eot_id|>\",'<|eom_id|>'],\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829f2569a068559d",
   "metadata": {},
   "source": [
    "##### Function to format user feedback in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a370e4ca60001b5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T04:28:34.334694Z",
     "start_time": "2025-03-04T04:28:34.314059Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_user_feedback(query, response, relevance, quality, comments=\"\"):\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"response\": response,\n",
    "        \"relevance\": int(relevance),\n",
    "        \"quality\": int(quality),\n",
    "        \"comments\": comments\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a8ffb33fab036c",
   "metadata": {},
   "source": [
    "##### Function to store the feedback in a json file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2a921daa4c88f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T04:28:34.357755Z",
     "start_time": "2025-03-04T04:28:34.339528Z"
    }
   },
   "outputs": [],
   "source": [
    "def store_feedback(feedback):\n",
    "    with open(\"../data/feedback_data.json\", \"a\") as f:\n",
    "        json.dump(feedback, f)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0956b6ff2119f35",
   "metadata": {},
   "source": [
    "##### Function to read the feedback file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8006d8445fd49326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T04:28:34.379551Z",
     "start_time": "2025-03-04T04:28:34.361978Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_feedback_data():\n",
    "    feedback_data = []\n",
    "    try:\n",
    "        with open(\"../data/feedback_data.json\", \"r\") as f:\n",
    "            for line in f:\n",
    "                feedback_data.append(json.loads(line.strip()))\n",
    "    except FileNotFoundError:\n",
    "        print(\"No feedback data file found. Starting with empty feedback.\")\n",
    "    return feedback_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386490846b07d08",
   "metadata": {},
   "source": [
    "##### Function to adjust files relevancy based on the feedbacks file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32c2541000349f24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T04:28:34.406020Z",
     "start_time": "2025-03-04T04:28:34.383798Z"
    }
   },
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    answer: str = Field(..., title=\"The answer to the question. The options can be only 'Yes' or 'No'\")\n",
    "\n",
    "def adjust_relevance_scores(query: str, docs: List[Any], feedback_data: List[Dict[str, Any]]) -> List[Any]:\n",
    "    # Create a prompt template for relevance checking\n",
    "    relevance_prompt = PromptTemplate(\n",
    "        input_variables=[\"query\", \"feedback_query\", \"doc_content\", \"feedback_response\"],\n",
    "        template=\"\"\"\n",
    "        Determine if the following feedback response is relevant to the current query and document content.\n",
    "        You are also provided with the Feedback original query that was used to generate the feedback response.\n",
    "        Current query: {query}\n",
    "        Feedback query: {feedback_query}\n",
    "        Document content: {doc_content}\n",
    "        Feedback response: {feedback_response}\n",
    "\n",
    "        Is this feedback relevant? Respond with only 'Yes' or 'No'.\n",
    "        \"\"\"\n",
    "    )\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key=\"EMPTY\",\n",
    "        openai_api_base=envs['VLLM_HOST_URL_2'] + \"/v1/\",\n",
    "        model_name=MODEL_NAME,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        streaming=True,\n",
    "        stop=[\"<|eot_id|>\",'<|eom_id|>'],\n",
    "    )\n",
    "\n",
    "    # Create an LLMChain for relevance checking\n",
    "    relevance_chain = relevance_prompt | llm.with_structured_output(Response)\n",
    "\n",
    "    for doc in docs:\n",
    "        relevant_feedback = []\n",
    "\n",
    "        for feedback in feedback_data:\n",
    "            # Use LLM to check relevance\n",
    "            input_data = {\n",
    "                \"query\": query,\n",
    "                \"feedback_query\": feedback['query'],\n",
    "                \"doc_content\": doc.page_content[:1000],\n",
    "                \"feedback_response\": feedback['response']\n",
    "            }\n",
    "            result = relevance_chain.invoke(input_data).answer\n",
    "\n",
    "            if result == 'yes':\n",
    "                relevant_feedback.append(feedback)\n",
    "\n",
    "        # Adjust the relevance score based on feedback\n",
    "        if relevant_feedback:\n",
    "            avg_relevance = sum(f['relevance'] for f in relevant_feedback) / len(relevant_feedback)\n",
    "            doc.metadata['relevance_score'] *= (avg_relevance / 3)  # Assuming a 1-5 scale, 3 is neutral\n",
    "\n",
    "    # Re-rank documents based on adjusted scores\n",
    "    return sorted(docs, key=lambda x: x.metadata['relevance_score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8030cd9b68349e0",
   "metadata": {},
   "source": [
    "##### Function to fine tune the vector index to include also queries + answers that received good feedbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aa0eb24cd685f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T04:28:34.429709Z",
     "start_time": "2025-03-04T04:28:34.410566Z"
    }
   },
   "outputs": [],
   "source": [
    "def fine_tune_index(feedback_data: List[Dict[str, Any]], texts: List[str]) -> Any:\n",
    "    # Filter high-quality responses\n",
    "    good_responses = [f for f in feedback_data if f['relevance'] >= 4 and f['quality'] >= 4]\n",
    "\n",
    "    # Extract queries and responses, and create new documents\n",
    "    additional_texts = []\n",
    "    for f in good_responses:\n",
    "        combined_text = f['query'] + \" \" + f['response']\n",
    "        additional_texts.append(combined_text)\n",
    "\n",
    "    # make the list a string\n",
    "    additional_texts = \" \".join(additional_texts)\n",
    "\n",
    "    # Create a new index with original and high-quality texts\n",
    "    all_texts = texts + additional_texts\n",
    "    new_vectorstore = encode_from_string(all_texts)\n",
    "\n",
    "    return new_vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e380bc62b1fce",
   "metadata": {},
   "source": [
    "##### Demonstration of how to retrieve answers with respect to user feedbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5be23364bac1337b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T04:29:25.100750Z",
     "start_time": "2025-03-04T04:28:34.434605Z"
    }
   },
   "outputs": [],
   "source": [
    "query = \"VKS là gì?\"\n",
    "\n",
    "# Get response from RAG system\n",
    "response = qa_chain.invoke(query)[\"result\"]\n",
    "\n",
    "relevance = 5\n",
    "quality = 5\n",
    "\n",
    "# Collect feedback\n",
    "feedback = get_user_feedback(query, response, relevance, quality)\n",
    "\n",
    "# Store feedback\n",
    "store_feedback(feedback)\n",
    "\n",
    "# Adjust relevance scores for future retrievals\n",
    "docs = retriever.invoke(query)\n",
    "adjusted_docs = adjust_relevance_scores(query, docs, load_feedback_data())\n",
    "\n",
    "# Update the retriever with adjusted docs\n",
    "retriever.search_kwargs['k'] = len(adjusted_docs)\n",
    "retriever.search_kwargs['docs'] = adjusted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46260d980bdaaad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T04:47:21.426466Z",
     "start_time": "2025-03-04T04:47:21.405025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Được rồi, người dùng đang hỏi \"VKS là gì?\". Từ thông tin mà tôi có, VKS là dịch vụ Kubernetes được quản lý bởi VNGCloud. Tôi cần giải thích rõ ràng và chi tiết để người dùng hiểu được VKS và những điểm nổi bật của nó.\n",
       "\n",
       "Đầu tiên, tôi应该 định nghĩa VKS là gì, giải thích rằng nó là dịch vụ Kubernetes được quản lý, giúp triển khai và quản lý ứng dụng container dễ dàng. Sau đó, tôi nên trình bày các điểm nổi bật như quản lý Control Plane tự động, hỗ trợ phiên bản mới, tích hợp Calico CNI, tự động nâng cấp và mở rộng, tiết kiệm chi phí, tích hợp storage và load balancer, cũng như bồi mật.\n",
       "\n",
       "Ngoài ra, kể về các region mà VKS cung cấp ở Hà Nội và Hồ Chí Minh也是 một điểm quan trọng. Cuối cùng, tôi cần đề cập đến các ưu điểm như dễ sử dụng và chi phí hợp lý, đồng thời cung cấp đường link để tham khảo thêm. Tôi phải sắp xếp thông tin này một cách logic và dễ hiểu để người dùng nắm rõ được VKS là gì và lợi ích của nó.\n",
       "</think>\n",
       "\n",
       "VNGCloud Kubernetes Service (VKS) là một dịch vụ quản lý Kubernetes được cung cấp bởi VNGCloud, giúp triển khai và quản lý các ứng dụng container một cách dễ dàng và hiệu quả. Dưới đây là một số điểm nổi bật của VKS:\n",
       "\n",
       "1. **Quản lý Control Plane tự động**: VKS miễn phí quản lý Control Plane, giúp người dùng tập trung vào phát triển ứng dụng.\n",
       "2. **Hỗ trợ phiên bản mới**: Cung cấp các phiên bản Kubernetes mới nhất (từ 1.27, 1.28, 1.29).\n",
       "3. **Tích hợp Calico CNI**: Mang lại hiệu suất và bảo mật cao trong Kubernetes Networking.\n",
       "4. **Nâng cấp dễ dàng**: Hỗ trợ nâng cấp phiên bản Kubernetes một cách nhanh chóng và không gây gián đoạn.\n",
       "5. **Tự động mở rộng và sửa lỗi**: Tự động mở rộng Node Group và tự động sửa lỗi khi có vấn đề về node.\n",
       "6. **Tiết kiệm chi phí và độ tin cậy cao**: Triển khai Control Plane với độ sẵn sàng cao và miễn phí.\n",
       "7. **Tích hợp Blockstore Native**: Quản lý Blockstore thông qua Kubernetes CSI, hỗ trợ các tính năng như thay đổi kích thước, IOPS và snapshot.\n",
       "8. **Tích hợp Load Balancer**: Quản lý NLB/ALB dễ dàng thông qua Kubernetes sử dụng các driver tích hợp sẵn.\n",
       "9. **Bảo mật cao**: Hỗ trợ tạo Private Node Group với kiểm soát truy cập dựa trên Whitelist IP.\n",
       "\n",
       "VKS hiện tại được cung cấp tại hai cơ sở hạ tầng ở Hà Nội và Hồ Chí Minh, cho phép người dùng lựa chọnbased on nhu cầu. Để tìm hiểu thêm, có thể tham khảo tại [đây](https://docs.vngcloud.vn/vng-cloud- document/vn/vks/vks-la-gi)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d63c95eb6fda291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T04:48:41.599545Z",
     "start_time": "2025-03-04T04:48:41.542523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1: 4c1f41cf-ca98-478b-b099-f76459539784 - {'relevance_score': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "1. Giới thiệu về VNGCloud Kubernetes\n",
       "Service - VKS\n",
       "1.1. VNGCloud Kubernetes Service (VKS) là gì?\n",
       "VNGCloud Kubernetes Service (hay còn gọi là VKS) là một dịch vụ quản lý Kubernetes được cung\n",
       "cấp bởi VNGCloud. VKS giúp bạn triển khai và quản lý các ứng dụng dựa trên container một cách\n",
       "dễ dàng và hiệu quả. VKS giúp bạn tập trung vào việc phát triển ứng dụng mà không cần quan tâm\n",
       "đến việc quản lý Control Plane của Kubernetes.\n",
       "VKS (VNGCloud Kubernetes Service) là một dịch vụ được quản lý trên VNGCloud giúp bạn đơn\n",
       "giản hóa quá trình triển khai và quản lý các ứng dụng dựa trên container. Kubernetes là một nền\n",
       "tảng mã nguồn mở được phát triển bởi Google, được sử dụng rộng rãi để quản lý và triển khai các\n",
       "ứng dụng container trên môi trường phân tán.\n",
       "1.2. Những điểm nổi bật của VKS\n",
       "Những điểm nổi bật của dịch vụ VKS có thể kể đến gồm:\n",
       "Quản lý Control Plane hoàn toàn tự động (Fully Managed control plane): VKS sẽ giải phóng\n",
       "bạn khỏi gánh nặng quản lý Control Plane của Kubernetes, giúp bạn tập trung vào việc phát\n",
       "triển ứng dụng.\n",
       "Hỗ trợ các phiên bản Kubernetes mới nhất: VKS luôn cập nhật những phiên bản Kubernetes\n",
       "mới nhất (minor version từ 1.27, 1.28, 1.29) để đảm bảo bạn luôn tận dụng được những tính\n",
       "năng tiên tiến nhất.\n",
       "Kubernetes Networking: VKS tích hợp Calico CNI, mang lại tính hiệu quả và bảo mật cao.\n",
       "Upgrade seamlessly: VKS hỗ trợ nâng cấp giữa các phiên bản Kubernetes một cách dễ dàng\n",
       "và nhanh chóng, giúp bạn luôn cập nhật những cải tiến mới nhất.\n",
       "Scaling & Healing Automatically: VKS tự động mở rộng Node group khi cần thiết và tự động\n",
       "sửa lỗi khi node gặp vấn đề, giúp bạn tiết kiệm thời gian và công sức quản lý.\n",
       "Giảm chi phí và nâng cao độ tin cậy: VKS triển khai Control Plane của Kubernetes ở chế độ\n",
       "sẵn sàng cao và hoàn toàn miễn phí, giúp bạn tiết kiệm chi phí và nâng cao độ tin cậy cho hệ\n",
       "thống.\n",
       "Tích hợp Blockstore Native (Container Storage Interface - CSI): VKS cho phép bạn quản lý\n",
       "Blockstore thông qua YAML của Kubernetes, cung cấp lưu trữ bền vững cho container và hỗ\n",
       "trợ các tính năng quan trọng như thay đổi kích thước, thay đổi IOPS và snapshot volume.\n",
       "Tích hợp Load Balancer (Network Load Balancer, Application Load Balancer) thông qua\n",
       "các driver được tích hợp sẵn như VNGCloud Controller Mananger, VNGCloud Ingress\n",
       "Controller: VKS cung cấp khả năng quản lý NLB/ALB thông qua YAML của Kubernetes, giúp\n",
       "bạn dễ dàng expose Service trong Kubernetes ra bên ngoài.\n",
       "Nâng cao bảo mật: VKS cho phép bạn tạo Private Node Group với chỉ Private IP và kiểm soát\n",
       "quyền truy cập vào cluster thông qua tính năng Whitelist IP, đảm bảo an toàn cho hệ thống của\n",
       "bạn.\n",
       "Ngoài ra, VKS còn có các ưu điểm sau:\n",
       "Dễ sử dụng: VKS cung cấp giao diện đơn giản và dễ sử dụng.\n",
       "Chi phí hợp lý: VKS cung cấp mức giá cạnh tranh cho các dịch vụ của mình.\n",
       "1.3. VKS cung cấp dịch vụ trên các khu vực (region)\n",
       "nào?\n",
       "Hiện tại, trên VKS, chúng tôi đang cung cấp cho bạn 2 cơ sở hạ tầng riêng biệt được đặt tại Hà Nội\n",
       "và Hồ Chí Minh. Bạn có thể lựa chọn sử dụng VKS trên mỗi region tùy thuộc vào vị trí và nhu cầu\n",
       "thực tế của bạn. Đối với 2 farm HCM03, HAN01, các thông số cụ thể cho mỗi region được chúng\n",
       "tôi cung cấp như sau:\n",
       "Khu vực Hồ Chí Minh (HCM03): https://vks.console.vngcloud.vn\n",
       "Khu vực Hà Nội (HAN01): https://vks-han-1.console.vngcloud.vn\n",
       "1.4. Tài liệu tham khảo:\n",
       "Bạn có thể tìm hiểu thêm về VKS tại đường dẫn https://docs.vngcloud.vn/vng-cloud-\n",
       "document/vn/vks/vks-la-gi"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, doc in enumerate(adjusted_docs):\n",
    "    print(f\"Document {i+1}: {doc.id} - {doc.metadata}\")\n",
    "    display(Markdown(doc.page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b105bae7dddd512",
   "metadata": {},
   "source": [
    "##### Finetune the vectorstore periodicly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee5c2c2287c58b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T04:50:49.744854Z",
     "start_time": "2025-03-04T04:50:42.690030Z"
    }
   },
   "outputs": [],
   "source": [
    "# Periodically (e.g., daily or weekly), fine-tune the index\n",
    "new_vectorstore = fine_tune_index(load_feedback_data(), content)\n",
    "retriever = new_vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4669284ac8b10bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
